{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "5mxcbgej4tj5dvxeqj3m",
   "authorId": "7704802563415",
   "authorName": "JRAUH",
   "authorEmail": "joshua.rauh@snowflake.com",
   "sessionId": "cc3dcd43-8892-494c-8dc8-0c1cfe420fae",
   "lastEditTime": 1760543903808
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "Introduction"
   },
   "source": "# ‚ùÑÔ∏è Hybrid Data Harmonization with AI_CLASSIFY\n\n**Purpose**: Advanced data harmonization using a two-stage approach that combines vector similarity with AI_CLASSIFY for optimal performance and cost efficiency.\n\n**Key Innovation**: This hybrid approach uses vector cosine similarity for high-confidence matches (‚â•0.8) and AI_CLASSIFY for medium-confidence cases, providing an amazing balance between speed, accuracy, and cost.\n\n**Why This Approach Works**:\n- **Fast Processing**: High-confidence matches are resolved quickly with vector similarity\n- **Intelligent Fallback**: AI_CLASSIFY handles ambiguous cases where vector similarity alone isn't sufficient\n- **Cost Optimization**: AI_CLASSIFY is only used when there are multiple candidates, reducing unnecessary API calls\n- **Proven Pattern**: Based on the successful embeddings + VECTOR_COSINE_SIMILARITY + AI_CLASSIFY workflow from Snowflake's AI SQL guide\n\n---\n"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "collapsed": false,
    "name": "Config_Explanation"
   },
   "source": [
    "## ‚ÑπÔ∏è  Configuration Setup and Environment Preparation\n",
    "\n",
    "**What This Cell Does**: This interactive configuration cell allows you to select your harmonization audit tables and entity columns for the hybrid matching process. It dynamically discovers available databases, schemas, and audit tables, then lets you choose which entity columns to use for matching. Once validated, it automatically sets up the Snowflake environment, prepares data structures, and extracts table/column information from the audit table.\n",
    "\n",
    "**Why This Is Important**: The hybrid approach needs to know which tables and columns contain your entity data to perform the two-stage matching process. This combined configuration and setup step ensures we're working with the right data sources, establishes the database context, and prepares all necessary variables for the feature engineering step. This streamlined approach eliminates an extra manual step and ensures the environment is ready immediately after configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "r_Harmonization_Table_Configuration"
   },
   "outputs": [],
   "source": "# Harmonization Table Configuration\n# Interactive selection of audit tables, harmonization tables, and entity columns\n\nimport streamlit as st\nimport pandas as pd\nfrom snowflake.snowpark.context import get_active_session\n\n# Get active session\nsession = get_active_session()\n\nst.title(\"üîß Hybrid Data Harmonization Configuration\")\nst.markdown(\"Configure your harmonization tables and entity columns for hybrid matching analysis.\")\n\n# Step 1: Database and Schema Selection\nst.header(\"1. Select Target Database and Schema\")\n\ncol1, col2 = st.columns(2)\n\ndef find_name_column(df, context=\"general\"):\n    \"\"\"Find the name column handling quoted column names\"\"\"\n    name_column = None\n    # Remove quotes from column names for comparison\n    clean_columns = {col.strip('\"\\'\\\\').upper(): col for col in df.columns}\n    \n    # Look for common name column patterns\n    patterns = ['NAME', 'DATABASE_NAME', 'DB_NAME', 'SCHEMA_NAME', 'TABLE_NAME']\n    \n    for pattern in patterns:\n        if pattern in clean_columns:\n            name_column = clean_columns[pattern]\n            break\n    \n    # If no standard patterns found, try to find any column with 'name' in it\n    if not name_column:\n        for clean_name, original_col in clean_columns.items():\n            if 'NAME' in clean_name:\n                name_column = original_col\n                break\n    \n    return name_column\n\nwith col1:\n    try:\n        # Get available databases\n        databases_df = session.sql(\"SHOW DATABASES\").to_pandas()\n        \n        if not databases_df.empty:\n            name_column = find_name_column(databases_df, \"database\")\n            \n            if name_column:\n                available_dbs = databases_df[name_column].tolist()\n                selected_db = st.selectbox(\"Database:\", available_dbs, index=0)\n            else:\n                st.error(\"‚ùå Could not find database name column. Available columns: \" + str(list(databases_df.columns)))\n                st.info(\"üîç Falling back to manual entry\")\n                selected_db = st.text_input(\"Database Name:\", value=\"ABT_BEST_BUY\")\n        else:\n            st.warning(\"‚ö†Ô∏è No databases found. Please check your permissions.\")\n            selected_db = None\n    except Exception as e:\n        st.error(f\"‚ùå An error occurred while fetching databases: {str(e)}\")\n        st.info(\"üîç Falling back to manual entry\")\n        selected_db = st.text_input(\"Database Name:\", value=\"ABT_BEST_BUY\")\n\nwith col2:\n    selected_schema = None\n    if selected_db:\n        try:\n            # Get schemas for selected database\n            schemas_df = session.sql(f\"SHOW SCHEMAS IN DATABASE {selected_db}\").to_pandas()\n            \n            if not schemas_df.empty:\n                name_column = find_name_column(schemas_df, \"schema\")\n                \n                if name_column:\n                    available_schemas = schemas_df[name_column].tolist()\n                    if available_schemas:\n                        selected_schema = st.selectbox(\"Schema:\", available_schemas, index=0)\n                    else:\n                        st.warning(\"‚ö†Ô∏è No schemas found in the selected database.\")\n                else:\n                    st.error(\"‚ùå Could not find schema name column. Available columns: \" + str(list(schemas_df.columns)))\n                    selected_schema = st.text_input(\"Schema Name:\", value=\"PUBLIC\")\n            else:\n                st.warning(\"‚ö†Ô∏è No schemas found in the selected database.\")\n                selected_schema = st.text_input(\"Schema Name:\", value=\"PUBLIC\")\n        except Exception as e:\n            st.error(f\"‚ùå An error occurred while fetching schemas: {str(e)}\")\n            st.info(\"üîç Falling back to manual entry\")\n            selected_schema = st.text_input(\"Schema Name:\", value=\"PUBLIC\")\n\nif selected_db and selected_schema:\n    # Set context\n    session.sql(f\"USE DATABASE {selected_db}\").collect()\n    session.sql(f\"USE SCHEMA {selected_schema}\").collect()\n    \n    st.success(f\"‚úÖ Context set to: {selected_db}.{selected_schema}\")\n    \n    # Step 2: Find Audit Tables\n    st.header(\"2. Select Harmonization Audit Table\")\n    \n    try:\n        # Look for audit harmonization tables\n        audit_tables_df = session.sql(\n            \"SHOW TABLES LIKE 'AUDIT_HARMONIZATION_%'\"\n        ).to_pandas()\n        \n        if not audit_tables_df.empty:\n            name_column = find_name_column(audit_tables_df, \"table\")\n            \n            if name_column:\n                audit_table_names = audit_tables_df[name_column].tolist()\n                \n                # Always show as dropdown, even if only one option\n                selected_audit_table = st.selectbox(\n                    \"Audit Table:\", \n                    audit_table_names,\n                    index=0,\n                    help=\"Select the audit table from your harmonization process\"\n                )\n            else:\n                st.error(\"‚ùå Could not find table name column. Available columns: \" + str(list(audit_tables_df.columns)))\n                selected_audit_table = None\n            \n            if selected_audit_table:\n                # Step 3: Load and Parse Audit Table\n                st.header(\"3. Configure Data Harmonization Columns\")\n                \n                # Load audit table data\n                audit_data_df = session.sql(f\"SELECT * FROM {selected_audit_table}\").to_pandas()\n                \n                # Handle case-insensitive column matching for audit data\n                col_mapping = {}\n                for col in audit_data_df.columns:\n                    col_clean = col.strip('\"\\'\\\\').upper()\n                    if col_clean == 'MATCHED_IN_OUTPUT':\n                        col_mapping['matched_in_output'] = col\n                    elif col_clean == 'REFERENCE_DATASET_COLUMN':\n                        col_mapping['reference_dataset_column'] = col\n                    elif col_clean == 'INPUT_DATASET_COLUMN':\n                        col_mapping['input_dataset_column'] = col\n                    elif col_clean == 'REFERENCE_DATASET':\n                        col_mapping['reference_dataset'] = col\n                    elif col_clean == 'INPUT_DATASET':\n                        col_mapping['input_dataset'] = col\n                    elif col_clean == 'REFERENCE_OUTPUT_TABLE':\n                        col_mapping['reference_output_table'] = col\n                    elif col_clean == 'INPUT_DATASET_TABLE':\n                        col_mapping['input_dataset_table'] = col\n                \n                # Check if we have all required columns\n                required_cols = ['matched_in_output', 'reference_dataset_column', 'input_dataset_column', \n                               'reference_output_table', 'input_dataset_table']\n                missing_cols = [col for col in required_cols if col not in col_mapping]\n                \n                if missing_cols:\n                    st.error(f\"‚ùå Missing required columns in audit table: {missing_cols}\")\n                    st.info(f\"Available columns: {list(audit_data_df.columns)}\")\n                else:\n                    # Filter only matched columns (case-insensitive)\n                    matched_filter = audit_data_df[col_mapping['matched_in_output']].str.upper() == 'YES'\n                    matched_columns = audit_data_df[matched_filter].copy()\n                    \n                    if not matched_columns.empty:\n                        st.subheader(\"Available Matched Columns:\")\n                        \n                        # Display matched columns in a nice format\n                        display_df = matched_columns[[\n                            col_mapping['reference_dataset_column'], \n                            col_mapping['input_dataset_column'],\n                            col_mapping.get('reference_dataset', col_mapping['reference_dataset_column']),\n                            col_mapping.get('input_dataset', col_mapping['input_dataset_column'])\n                        ]].copy()\n                        \n                        display_df.columns = ['Reference Column', 'Input Column', 'Reference Source', 'Input Source']\n                        st.dataframe(display_df, use_container_width=True)\n                        \n                        # Step 4: Select Entity Column for Analysis\n                        st.subheader(\"Select Primary Entity Column for Matching:\")\n                        \n                        # Create options showing both reference and input columns\n                        column_options = []\n                        for idx, row in matched_columns.iterrows():\n                            ref_col = row[col_mapping['reference_dataset_column']]\n                            inp_col = row[col_mapping['input_dataset_column']]\n                            option_label = f\"{ref_col} ‚Üî {inp_col}\"\n                            column_options.append((option_label, ref_col, inp_col))\n                        \n                        if len(column_options) == 1:\n                            selected_option = column_options[0]\n                            st.info(f\"üìù Auto-selected entity columns: {selected_option[0]}\")\n                        else:\n                            option_labels = [opt[0] for opt in column_options]\n                            selected_idx = st.selectbox(\n                                \"Entity Column Pair:\",\n                                range(len(option_labels)),\n                                format_func=lambda x: option_labels[x],\n                                help=\"Select the column pair that contains the primary entity names/labels for matching\"\n                            )\n                            selected_option = column_options[selected_idx]\n                        \n                        # Helper function to properly quote table identifiers\n                        def quote_table_identifier(table_path):\n                            \"\"\"Ensures table path components are properly quoted for case-sensitive names\"\"\"\n                            if not table_path:\n                                return table_path\n                            \n                            # Remove existing quotes first\n                            table_path_clean = table_path.replace('\"', '')\n                            \n                            # Split into parts (database.schema.table)\n                            parts = table_path_clean.split('.')\n                            \n                            # Quote each part that needs it (contains lowercase, special chars, or starts with digit)\n                            quoted_parts = []\n                            for part in parts:\n                                part = part.strip()\n                                # Check if quoting is needed (has lowercase letters or special chars)\n                                needs_quotes = any(c.islower() or not (c.isalnum() or c == '_') for c in part)\n                                if needs_quotes:\n                                    quoted_parts.append(f'\"{part}\"')\n                                else:\n                                    quoted_parts.append(part)\n                            \n                            return '.'.join(quoted_parts)\n                        \n                        # Get table information from audit table\n                        ref_table_from_audit = matched_columns.iloc[0][col_mapping['reference_output_table']]\n                        inp_table_from_audit = matched_columns.iloc[0][col_mapping['input_dataset_table']]\n                        \n                        # Properly quote the table names\n                        ref_table_from_audit = quote_table_identifier(ref_table_from_audit)\n                        inp_table_from_audit = quote_table_identifier(inp_table_from_audit)\n                        \n                        # Step 5: Verify and Edit Table Names\n                        st.subheader(\"Verify Source Table Names:\")\n                        st.caption(\"‚ö†Ô∏è Confirm these table names are correct. Edit them if needed before saving configuration.\")\n                        \n                        col_ref, col_inp = st.columns(2)\n                        \n                        with col_ref:\n                            ref_table_input = st.text_input(\n                                \"Reference Table (Fully Qualified):\",\n                                value=ref_table_from_audit,\n                                help=\"Full table path: DATABASE.SCHEMA.TABLE_NAME (quotes added automatically for mixed-case names)\"\n                            )\n                        \n                        with col_inp:\n                            inp_table_input = st.text_input(\n                                \"Input Table (Fully Qualified):\",\n                                value=inp_table_from_audit,\n                                help=\"Full table path: DATABASE.SCHEMA.TABLE_NAME (quotes added automatically for mixed-case names)\"\n                            )\n                        \n                        # Show warning if tables were edited\n                        if ref_table_input != ref_table_from_audit or inp_table_input != inp_table_from_audit:\n                            st.warning(\"‚ö†Ô∏è Table names have been modified from the audit table values. Make sure they are correct!\")\n                        \n                        # Validate that tables exist\n                        if st.button(\"‚úÖ Validate, Save Configuration, and Set Up Environment\"):\n                            errors = []\n                            \n                            # Ensure input table names are properly quoted\n                            ref_table_quoted = quote_table_identifier(ref_table_input)\n                            inp_table_quoted = quote_table_identifier(inp_table_input)\n                            \n                            # Try to query the tables to verify they exist\n                            try:\n                                session.sql(f\"SELECT 1 FROM {ref_table_quoted} LIMIT 1\").collect()\n                                st.success(f\"‚úÖ Reference table validated: {ref_table_quoted}\")\n                            except Exception as e:\n                                errors.append(f\"‚ùå Reference table not found: {ref_table_quoted}\")\n                                errors.append(f\"   Error details: {str(e)}\")\n                            \n                            try:\n                                session.sql(f\"SELECT 1 FROM {inp_table_quoted} LIMIT 1\").collect()\n                                st.success(f\"‚úÖ Input table validated: {inp_table_quoted}\")\n                            except Exception as e:\n                                errors.append(f\"‚ùå Input table not found: {inp_table_quoted}\")\n                                errors.append(f\"   Error details: {str(e)}\")\n                            \n                            if errors:\n                                for error in errors:\n                                    st.error(error)\n                                st.info(\"üí° Please correct the table names and try again. Make sure the tables exist and you have access permissions.\")\n                            else:\n                                # Store configuration with properly quoted table names\n                                config = {\n                                    'database': selected_db,\n                                    'schema': selected_schema,\n                                    'audit_table': selected_audit_table,\n                                    'reference_table': ref_table_quoted,\n                                    'input_table': inp_table_quoted,\n                                    'reference_entity_column': selected_option[1],\n                                    'input_entity_column': selected_option[2],\n                                    'matched_columns_count': len(matched_columns)\n                                }\n                                \n                                # Store in a TEMPORARY table (auto-drops at session end) for use by subsequent cells\n                                config_df = pd.DataFrame([config])\n                                \n                                # Create temporary table using Snowpark DataFrame API\n                                session.create_dataframe(config_df).write.save_as_table(\n                                    'TEMP_HYBRID_CONFIG',\n                                    mode='overwrite',\n                                    table_type='temporary'  # Creates a true TEMPORARY table that auto-drops\n                                )\n                                \n                                st.success(\"‚úÖ Configuration validated and saved!\")\n                                st.markdown(f\"\"\"\n                                **Saved Configuration:**\n                                - Reference Table: `{ref_table_quoted}`\n                                - Input Table: `{inp_table_quoted}`\n                                - Reference Entity Column: `{selected_option[1]}`\n                                - Input Entity Column: `{selected_option[2]}`\n                                \"\"\")\n                                \n                                # --- BEGIN ENVIRONMENT SETUP (formerly r_Environment_Set_Up cell) ---\n                                st.info(\"üîß Setting up environment and preparing data structures...\")\n                                \n                                try:\n                                    # Clear all caches and ensure fresh start\n                                    session.sql(\"ALTER SESSION SET USE_CACHED_RESULT = FALSE\").collect()\n                                    session.sql(\"ALTER SESSION SET QUERY_TAG = 'HYBRID_ENTITY_MATCHING_WITH_AI_CLASSIFY'\").collect()\n                                    \n                                    # Drop any existing temporary tables to avoid conflicts\n                                    session.sql(\"DROP TABLE IF EXISTS config_data_hybrid\").collect()\n                                    session.sql(\"DROP TABLE IF EXISTS audit_info_hybrid\").collect()\n                                    session.sql(\"DROP TABLE IF EXISTS hybrid_features\").collect()\n                                    session.sql(\"DROP TABLE IF EXISTS hybrid_final_results\").collect()\n                                    \n                                    # Get the configuration from the temporary table\n                                    session.sql(\"\"\"\n                                        CREATE OR REPLACE TEMPORARY TABLE config_data_hybrid AS\n                                        SELECT * FROM TEMP_HYBRID_CONFIG LIMIT 1\n                                    \"\"\").collect()\n                                    \n                                    # Set context based on configuration\n                                    session.sql(f\"\"\"\n                                        SET (db_name, schema_name) = (SELECT \"database\", \"schema\" FROM config_data_hybrid)\n                                    \"\"\").collect()\n                                    session.sql(\"USE DATABASE IDENTIFIER($db_name)\").collect()\n                                    session.sql(\"USE SCHEMA IDENTIFIER($schema_name)\").collect()\n                                    \n                                    # Get table and column information\n                                    session.sql(\"\"\"\n                                        SET (ref_entity_col, inp_entity_col, audit_table_name) = (\n                                            SELECT \n                                                \"reference_entity_column\",\n                                                \"input_entity_column\",\n                                                \"audit_table\"\n                                            FROM config_data_hybrid\n                                        )\n                                    \"\"\").collect()\n                                    \n                                    # Get the matched columns from the audit table\n                                    session.sql(\"\"\"\n                                        CREATE OR REPLACE TEMPORARY TABLE column_mappings_hybrid AS\n                                        SELECT \n                                            REFERENCE_DATASET_COLUMN as ref_col,\n                                            INPUT_DATASET_COLUMN as inp_col\n                                        FROM IDENTIFIER($audit_table_name)\n                                        WHERE UPPER(MATCHED_IN_OUTPUT) = 'YES'\n                                    \"\"\").collect()\n                                    \n                                    # Build dynamic column lists\n                                    session.sql(\"\"\"\n                                        CREATE OR REPLACE TEMPORARY TABLE ref_columns_hybrid AS\n                                        SELECT LISTAGG(ref_col, ', ') as ref_select_list\n                                        FROM column_mappings_hybrid\n                                        WHERE ref_col != 'COLLATED_COLUMN'\n                                    \"\"\").collect()\n                                    \n                                    session.sql(\"\"\"\n                                        CREATE OR REPLACE TEMPORARY TABLE inp_columns_hybrid AS  \n                                        SELECT LISTAGG(inp_col, ', ') as inp_select_list\n                                        FROM column_mappings_hybrid\n                                        WHERE inp_col != 'COLLATED_COLUMN'\n                                    \"\"\").collect()\n                                    \n                                    # Get all matched columns and table names dynamically\n                                    session.sql(\"\"\"\n                                        CREATE OR REPLACE TEMPORARY TABLE audit_info_hybrid AS\n                                        SELECT \n                                            REFERENCE_DATASET_COLUMN as ref_col,\n                                            INPUT_DATASET_COLUMN as inp_col,\n                                            CASE \n                                                WHEN REFERENCE_OUTPUT_TABLE LIKE '%.%.%' THEN SPLIT_PART(REFERENCE_OUTPUT_TABLE, '.', 3)\n                                                WHEN REFERENCE_OUTPUT_TABLE LIKE '%.%' THEN SPLIT_PART(REFERENCE_OUTPUT_TABLE, '.', 2)\n                                                ELSE REFERENCE_OUTPUT_TABLE\n                                            END as ref_table,\n                                            CASE \n                                                WHEN INPUT_DATASET_TABLE LIKE '%.%.%' THEN SPLIT_PART(INPUT_DATASET_TABLE, '.', 3)\n                                                WHEN INPUT_DATASET_TABLE LIKE '%.%' THEN SPLIT_PART(INPUT_DATASET_TABLE, '.', 2)\n                                                ELSE INPUT_DATASET_TABLE\n                                            END as inp_table,\n                                            REFERENCE_OUTPUT_TABLE as ref_table_full,\n                                            INPUT_DATASET_TABLE as inp_table_full,\n                                            ROW_NUMBER() OVER (ORDER BY REFERENCE_DATASET_COLUMN) as rn\n                                        FROM IDENTIFIER($audit_table_name) \n                                        WHERE UPPER(MATCHED_IN_OUTPUT) = 'YES'\n                                    \"\"\").collect()\n                                    \n                                    # Set dynamic variables for table names and columns\n                                    session.sql(\"\"\"\n                                        SET (ref_table_name, inp_table_name, ref_col1, inp_col1, ref_col2, inp_col2, ref_col3, inp_col3, ref_table_full_name, inp_table_full_name) = (\n                                            SELECT \n                                                MAX(CASE WHEN rn = 1 THEN ref_table END),\n                                                MAX(CASE WHEN rn = 1 THEN inp_table END),\n                                                MAX(CASE WHEN rn = 1 THEN ref_col END),\n                                                MAX(CASE WHEN rn = 1 THEN inp_col END),\n                                                MAX(CASE WHEN rn = 2 THEN ref_col END),\n                                                MAX(CASE WHEN rn = 2 THEN inp_col END),\n                                                MAX(CASE WHEN rn = 3 THEN ref_col END),\n                                                MAX(CASE WHEN rn = 3 THEN inp_col END),\n                                                (SELECT \"reference_table\" FROM config_data_hybrid),\n                                                (SELECT \"input_table\" FROM config_data_hybrid)\n                                            FROM audit_info_hybrid\n                                        )\n                                    \"\"\").collect()\n                                    \n                                    # Display configuration summary\n                                    summary_df = session.sql(\"\"\"\n                                        SELECT \n                                            'SETUP COMPLETE' as status,\n                                            $ref_table_full_name as reference_table_used,\n                                            $inp_table_full_name as input_table_used,\n                                            $ref_entity_col as reference_entity_column,\n                                            $inp_entity_col as input_entity_column,\n                                            'Ready for hybrid feature engineering' as next_step\n                                    \"\"\").to_pandas()\n                                    \n                                    st.success(\"‚úÖ Environment setup complete!\")\n                                    st.dataframe(summary_df, use_container_width=True)\n                                    st.info(\"‚ú® You can now proceed to the Vector Feature Engineering cell.\")\n                                    \n                                except Exception as setup_error:\n                                    st.error(f\"‚ùå Error during environment setup: {str(setup_error)}\")\n                                    st.info(\"Configuration was saved, but environment setup failed. You may need to run the setup manually.\")\n                                # --- END ENVIRONMENT SETUP ---\n                        \n                    \n                        \n                    else:\n                        st.warning(\"‚ö†Ô∏è No matched columns found in the audit table. Make sure 'MATCHED_IN_OUTPUT' column contains 'Yes' values.\")\n        else:\n            st.warning(f\"‚ö†Ô∏è No audit tables found matching pattern 'AUDIT_HARMONIZATION_%' in {selected_db}.{selected_schema}\")\n            st.info(\"üí° Make sure you've run the Snowflake Data Harmonization Streamlit app first to generate audit tables.\")\n    \n    except Exception as e:\n        st.error(f\"‚ùå Error accessing audit tables: {str(e)}\")\n        st.info(\"üîç Debug info: Check if the audit table exists and you have proper permissions\")\nelse:\n    st.info(\"üëÜ Please select a database and schema to continue.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "collapsed": false,
    "name": "Vector_Explanation"
   },
   "source": [
    "## ‚ÑπÔ∏è  Vector Feature Engineering\n",
    "\n",
    "**What This Cell Does**: This cell creates the foundational features needed for the hybrid matching approach. It generates vector embeddings for both reference and input entity names using Snowflake's CORTEX.EMBED_TEXT_1024 function, performs basic text cleaning and standardization, and creates a cross-join of all possible entity pairs with their similarity scores.\n",
    "\n",
    "**Why This Is Important**: The hybrid approach relies on vector similarity as its primary matching mechanism. This feature engineering step creates the vector embeddings that will be used in both stages of the matching process - for high-confidence direct matches and as input to AI_CLASSIFY for medium-confidence cases. The text cleaning ensures consistent comparison, and the similarity filtering reduces the search space for more efficient processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "language": "sql",
    "name": "r_Vector_Feature_Engineering",
    "vscode": {
     "languageId": "sql"
    },
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "-- Vector Feature Engineering for Hybrid Matching\n",
    "-- Creates vector embeddings and similarity scores for the two-stage matching process\n",
    "\n",
    "-- Create the hybrid_features table with vector embeddings\n",
    "CREATE OR REPLACE TABLE hybrid_features AS\n",
    "WITH reference_features AS (\n",
    "    SELECT \n",
    "        -- Core entity matching columns (dynamically selected)\n",
    "        IDENTIFIER($ref_col1) as REF_COL1,\n",
    "        IDENTIFIER($ref_col2) as REF_COL2,\n",
    "        IDENTIFIER($ref_col3) as REF_COL3,\n",
    "        -- Entity name and cleaned version for matching\n",
    "        IDENTIFIER($ref_entity_col) as REF_RAW_NAME,\n",
    "        -- Pre-compute vector embedding for performance\n",
    "        SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2', IDENTIFIER($ref_entity_col)) as REF_EMBEDDING\n",
    "    FROM IDENTIFIER($ref_table_full_name)\n",
    "),\n",
    "input_features AS (\n",
    "    SELECT \n",
    "        -- Core entity matching columns (dynamically selected) \n",
    "        IDENTIFIER($inp_col1) as INP_COL1,\n",
    "        IDENTIFIER($inp_col2) as INP_COL2,\n",
    "        IDENTIFIER($inp_col3) as INP_COL3,\n",
    "        -- Entity name and cleaned version for matching\n",
    "        IDENTIFIER($inp_entity_col) as INP_RAW_NAME,\n",
    "       -- Pre-compute vector embedding for performance\n",
    "        SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2', IDENTIFIER($inp_entity_col)) as INP_EMBEDDING\n",
    "    FROM IDENTIFIER($inp_table_full_name)\n",
    ")\n",
    "SELECT \n",
    "    -- Reference table columns with REF_ prefix\n",
    "    ref.REF_COL1,\n",
    "    ref.REF_COL2,\n",
    "    ref.REF_COL3,\n",
    "    ref.REF_RAW_NAME,\n",
    "    ref.REF_EMBEDDING,\n",
    "    -- Input table columns with INP_ prefix  \n",
    "    inp.INP_COL1,\n",
    "    inp.INP_COL2,\n",
    "    inp.INP_COL3,\n",
    "    inp.INP_RAW_NAME,\n",
    "    inp.INP_EMBEDDING,\n",
    "    -- Pre-compute vector similarity for efficiency\n",
    "    VECTOR_COSINE_SIMILARITY(ref.REF_EMBEDDING, inp.INP_EMBEDDING) as vector_similarity\n",
    "FROM reference_features ref\n",
    "CROSS JOIN input_features inp\n",
    "-- Filter out very low similarity pairs to improve performance\n",
    "WHERE VECTOR_COSINE_SIMILARITY(ref.REF_EMBEDDING, inp.INP_EMBEDDING) > 0.2;\n",
    "\n",
    "-- Show the performance and configuration used\n",
    "SELECT \n",
    "    'HYBRID VECTOR FEATURES ENGINEERING COMPLETE' as method,\n",
    "    COUNT(*) as total_comparisons,\n",
    "    COUNT(DISTINCT REF_RAW_NAME) as reference_products,\n",
    "    COUNT(DISTINCT INP_RAW_NAME) as input_products,\n",
    "    ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT REF_RAW_NAME), 1) as avg_comparisons_per_reference_product,\n",
    "    ROUND(AVG(vector_similarity), 3) as avg_vector_similarity,\n",
    "    $ref_table_full_name as reference_table_used,\n",
    "    $inp_table_full_name as input_table_used,\n",
    "    $ref_entity_col as reference_entity_column,\n",
    "    $inp_entity_col as input_entity_column,\n",
    "    'Vector embeddings ready for hybrid matching process' as note\n",
    "FROM hybrid_features;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "collapsed": false,
    "name": "Hybrid_Matching_Explanation"
   },
   "source": "## ‚ÑπÔ∏è  Hybrid Matching: Vector Similarity + AI_CLASSIFY\n\n**What This Cell Does**: This is the core of the hybrid approach, implementing the two-stage matching process. First, it identifies high-confidence matches that can be resolved immediately. Then, for medium-confidence cases, it uses AI_CLASSIFY to select the best match from the top-15 candidates array. This approach combines the speed of vector similarity with the intelligence of AI_CLASSIFY for optimal performance.\n\n**Why This Is Important**: This hybrid approach provides the best balance between speed, accuracy, and cost. High-confidence matches are resolved quickly without expensive AI_CLASSIFY calls, while medium-confidence cases benefit from AI_CLASSIFY's ability to understand context and make intelligent decisions. This pattern is inspired by the successful AI_SIMILARITY + AI_CLASSIFY workflow and ensures that AI_CLASSIFY is only used when there are multiple viable candidates.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "language": "sql",
    "name": "r_Hybrid_Matching",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Hybrid Matching: Vector Similarity + AI_CLASSIFY\n",
    "-- Implements the two-stage matching process for optimal performance and cost efficiency\n",
    "\n",
    "CREATE OR REPLACE TABLE hybrid_final_results AS\n",
    "WITH top_k_candidates AS (\n",
    "    -- Get top 15 candidates per reference product for AI_CLASSIFY\n",
    "    SELECT \n",
    "      \n",
    "        hf.REF_RAW_NAME,\n",
    "        hf.INP_RAW_NAME,\n",
    "        hf.REF_COL1,\n",
    "        hf.INP_COL1,\n",
    "        hf.REF_COL2,\n",
    "        hf.INP_COL2,\n",
    "        hf.REF_COL3,\n",
    "        hf.INP_COL3,\n",
    "        hf.vector_similarity,\n",
    "        ROW_NUMBER() OVER (PARTITION BY hf.REF_RAW_NAME ORDER BY hf.vector_similarity DESC) as rank\n",
    "    FROM hybrid_features hf\n",
    "    WHERE hf.vector_similarity > 0.3  -- Basic threshold for candidate selection\n",
    "),\n",
    "\n",
    "-- Aggregate top K candidates for AI_CLASSIFY\n",
    "agg_candidates AS (\n",
    "    SELECT \n",
    "       \n",
    "        REF_RAW_NAME,\n",
    "        ARRAY_AGG(INP_RAW_NAME) WITHIN GROUP (ORDER BY rank) as candidate_names,\n",
    "        COUNT(*) as candidate_count\n",
    "    FROM top_k_candidates\n",
    "    WHERE rank <= 15  -- Top 15 candidates for AI_CLASSIFY\n",
    "    GROUP BY  REF_RAW_NAME\n",
    "),\n",
    "\n",
    "-- Apply AI_CLASSIFY for medium confidence matches\n",
    "ai_classified AS (\n",
    "    SELECT \n",
    "     \n",
    "        ac.REF_RAW_NAME,\n",
    "        ac.candidate_names,\n",
    "        ac.candidate_count,\n",
    "        -- Apply AI_CLASSIFY only if we have multiple candidates\n",
    "        CASE \n",
    "            WHEN ac.candidate_count >= 2 THEN\n",
    "                GET(AI_CLASSIFY(ac.REF_RAW_NAME, ac.candidate_names):\"labels\", 0)::string\n",
    "            ELSE ac.candidate_names[0]::string\n",
    "        END as ai_selected_match,\n",
    "        -- Mark if AI_CLASSIFY was used\n",
    "        CASE WHEN ac.candidate_count >= 2 THEN 1 ELSE 0 END as ai_classify_used\n",
    "    FROM agg_candidates ac\n",
    "),\n",
    "\n",
    "-- Get the final results with confidence scoring\n",
    "final_scoring AS (\n",
    "    SELECT \n",
    "        tc.REF_RAW_NAME,\n",
    "        tc.INP_RAW_NAME,\n",
    "        tc.REF_COL1,\n",
    "        tc.INP_COL1,\n",
    "        tc.REF_COL2,\n",
    "        tc.INP_COL2,\n",
    "        tc.REF_COL3,\n",
    "        tc.INP_COL3,\n",
    "        tc.vector_similarity,\n",
    "        tc.rank,\n",
    "        ac.ai_selected_match,\n",
    "        ac.ai_classify_used,\n",
    "        -- Use AI_CLASSIFY result if it matches, otherwise use top vector match\n",
    "        CASE \n",
    "            WHEN ac.ai_selected_match = tc.INP_RAW_NAME THEN ac.ai_selected_match\n",
    "            WHEN tc.rank = 1 THEN tc.INP_RAW_NAME\n",
    "            ELSE NULL\n",
    "        END as final_match,\n",
    "        -- Enhanced confidence: boost AI_CLASSIFY matches slightly\n",
    "        CASE \n",
    "            WHEN ac.ai_selected_match = tc.INP_RAW_NAME THEN \n",
    "                LEAST(1.0, tc.vector_similarity + 0.1)\n",
    "            ELSE tc.vector_similarity\n",
    "        END as enhanced_confidence\n",
    "    FROM top_k_candidates tc\n",
    "    LEFT JOIN ai_classified ac ON tc.REF_RAW_NAME = ac.REF_RAW_NAME\n",
    "),\n",
    "\n",
    "-- Get the best match per reference product\n",
    "best_matches AS (\n",
    "    SELECT \n",
    "        \n",
    "        final_match,\n",
    "        enhanced_confidence,\n",
    "        REF_RAW_NAME as reference_entity_name,\n",
    "        INP_RAW_NAME as input_entity_name,\n",
    "        vector_similarity,\n",
    "        ai_classify_used,\n",
    "        -- Determine match method\n",
    "        CASE \n",
    "            WHEN ai_classify_used = 1 AND final_match = ai_selected_match THEN 'AI_CLASSIFY'\n",
    "            WHEN vector_similarity >= 0.8 THEN 'HIGH_CONFIDENCE_VECTOR'\n",
    "            ELSE 'MEDIUM_CONFIDENCE_VECTOR'\n",
    "        END as match_method,\n",
    "        -- Include key identifier columns for evaluation\n",
    "        REF_COL1 as reference_id_column,\n",
    "        INP_COL1 as input_id_column,\n",
    "        REF_COL2 as reference_label_column,\n",
    "        INP_COL2 as input_label_column,\n",
    "        REF_COL3 as reference_detail_column,\n",
    "        INP_COL3 as input_detail_column,\n",
    "        rank,\n",
    "        -- No brand/model matching in hybrid version\n",
    "        0 as brand_exact_match,\n",
    "        0 as model_exact_match\n",
    "    FROM final_scoring\n",
    "    WHERE final_match IS NOT NULL\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY REF_RAW_NAME ORDER BY enhanced_confidence DESC) = 1\n",
    ")\n",
    "\n",
    "SELECT * FROM best_matches;\n",
    "\n",
    "-- Performance summary\n",
    "SELECT \n",
    "    'HYBRID VECTOR + AI_CLASSIFY MATCHING COMPLETE' as method,\n",
    "    COUNT(*) as total_matches,\n",
    "    ROUND(AVG(enhanced_confidence), 3) as avg_confidence,\n",
    "    ROUND(AVG(vector_similarity), 3) as avg_vector_similarity,\n",
    "    COUNT(CASE WHEN enhanced_confidence >= 0.8 THEN 1 END) as high_confidence_matches,\n",
    "    SUM(ai_classify_used) as ai_classify_used_count,\n",
    "    ROUND(SUM(ai_classify_used) * 100.0 / COUNT(*), 2) as ai_classify_usage_percent,\n",
    "    COUNT(CASE WHEN match_method = 'AI_CLASSIFY' THEN 1 END) as ai_classify_matches,\n",
    "    COUNT(CASE WHEN match_method = 'HIGH_CONFIDENCE_VECTOR' THEN 1 END) as high_confidence_vector_matches,\n",
    "    COUNT(CASE WHEN match_method = 'MEDIUM_CONFIDENCE_VECTOR' THEN 1 END) as medium_confidence_vector_matches\n",
    "FROM hybrid_final_results;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280a944-a26a-4139-8468-897441e5dd4e",
   "metadata": {
    "collapsed": false,
    "name": "Record_Management_Evalution"
   },
   "source": [
    "## ‚ÑπÔ∏è Record Management and Threshold Selection\n",
    "\n",
    "**What This Cell Does**: This interactive cell allows you to review the confidence distribution of your hybrid matching results and select a confidence threshold to separate records into MATCHED and UNMATCHED tables. You can also customize the table names before creation.\n",
    "\n",
    "**Why This Is Important**: Not all matches require the same level of confidence for different business use cases. This cell gives you control over what gets accepted as a match versus what needs further review. The ability to customize table names ensures the output tables fit your naming conventions and workflow requirements. Using CREATE OR REPLACE ensures you can re-run the process with different thresholds without manual cleanup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575de5dc-5dcd-4859-a818-9927efe46c94",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "r_Record_Management"
   },
   "outputs": [],
   "source": [
    "# Record Management - Confidence Threshold Selection and Table Creation\n",
    "# Interactive Streamlit interface for selecting confidence thresholds and creating matched/unmatched tables\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import numpy as np\n",
    "import altair as alt # Import Altair for advanced charting controls\n",
    "\n",
    "# Get active session\n",
    "session = get_active_session()\n",
    "\n",
    "# Setting a cleaner title and description for the section\n",
    "st.title(\"üîó Hybrid Matching - Finalize Records\")\n",
    "st.markdown(\"Select a confidence threshold to separate records into **MATCHED** and **UNMATCHED** output tables.\")\n",
    "\n",
    "# --- Configuration Check ---\n",
    "try:\n",
    "    # Safely retrieve configuration from the temporary table\n",
    "    config_df = session.sql(\"SELECT * FROM TEMP_HYBRID_CONFIG LIMIT 1\").to_pandas()\n",
    "    if config_df.empty:\n",
    "        st.error(\"‚ùå Configuration not found. Please run the setup cell first.\")\n",
    "        st.stop()\n",
    "    audit_table_name = config_df.iloc[0]['audit_table']\n",
    "    results_table_name = \"hybrid_final_results\"\n",
    "\n",
    "    # Quick check for results table existence (will throw error if not found)\n",
    "    session.sql(f\"SELECT 1 FROM {results_table_name} LIMIT 1\").collect()\n",
    "\n",
    "except Exception as e:\n",
    "    st.error(f\"‚ùå Error initializing. Ensure the configuration and hybrid matching cells were run successfully: {str(e)}\")\n",
    "    st.stop()\n",
    "\n",
    "\n",
    "# --- 1. Confidence Distribution Visualization ---\n",
    "st.header(\"1. Confidence Distribution Analysis\")\n",
    "st.markdown(\"Visualize the distribution of match quality before setting your threshold.\")\n",
    "\n",
    "try:\n",
    "    # Fetch data for visualization and breakdown\n",
    "    # Binning data. Store confidence as a float for charting/sorting.\n",
    "    # Note: The SQL query still bins by 0.1 (10%), but Altair controls its display.\n",
    "    confidence_data_sf = session.sql(f\"\"\"\n",
    "        SELECT \n",
    "            FLOOR(enhanced_confidence * 10) / 10 AS confidence_bin_float,\n",
    "            COUNT(*) AS record_count\n",
    "        FROM {results_table_name}\n",
    "        GROUP BY 1\n",
    "        ORDER BY 1 DESC\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    # Calculate percentage string for display in the table\n",
    "    confidence_data_sf.columns = ['Confidence Bin Float', 'Record Count']\n",
    "    confidence_data_sf['Confidence Bin Float'] = confidence_data_sf['Confidence Bin Float'].astype(float)\n",
    "\n",
    "    col_chart, col_table = st.columns([7, 3])\n",
    "\n",
    "    with col_chart:\n",
    "        st.subheader(\"Match Count by Confidence Bin\")\n",
    "        \n",
    "        # --- Altair Chart for Snappier Look and Percentage Formatting ---\n",
    "        chart = alt.Chart(confidence_data_sf).mark_bar().encode(\n",
    "            # X-axis: Use the float for binning, format label as percentage\n",
    "            x=alt.X('Confidence Bin Float', \n",
    "                    title='Minimum Enhanced Confidence',\n",
    "                    bin=alt.Bin(step=0.1), # Explicitly set bin step to 0.1 (10%)\n",
    "                    axis=alt.Axis(format='.0%') \n",
    "                   ),\n",
    "            y=alt.Y('Record Count', \n",
    "                    title='Record Count',\n",
    "                    axis=alt.Axis(grid=False) # Remove horizontal gridlines\n",
    "                   ),\n",
    "            tooltip=[\n",
    "                alt.Tooltip('Confidence Bin Float', title='Min Confidence', format='.1%'), \n",
    "                'Record Count'\n",
    "            ]\n",
    "        ).properties(\n",
    "            height=300\n",
    "        ).configure_view(\n",
    "            stroke='transparent' # Remove outer border\n",
    "        ).configure_axis(\n",
    "            grid=False, # Remove vertical gridlines\n",
    "            domainColor='gray',\n",
    "            tickColor='gray',\n",
    "            titleFontWeight='bold'\n",
    "        )\n",
    "\n",
    "        st.altair_chart(chart, use_container_width=True)\n",
    "        # --- End Altair Chart ---\n",
    "\n",
    "    with col_table:\n",
    "        st.subheader(\"Summary Table\")\n",
    "        # Add Percentage of Total\n",
    "        total_records = confidence_data_sf['Record Count'].sum()\n",
    "        confidence_data_sf['% of Total'] = (confidence_data_sf['Record Count'] / total_records * 100).round(1).astype(str) + '%'\n",
    "        \n",
    "        # Calculate percentage string for display in the table\n",
    "        display_df = confidence_data_sf.copy()\n",
    "        # Display bin as a percentage (e.g., 0.9 -> 90%)\n",
    "        display_df['Min Confidence'] = (display_df['Confidence Bin Float'] * 100).astype(int).astype(str) + '%'\n",
    "        \n",
    "        st.dataframe(\n",
    "            display_df[['Min Confidence', 'Record Count', '% of Total']],\n",
    "            use_container_width=True,\n",
    "            hide_index=True\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    st.error(f\"‚ùå Error generating confidence breakdown visualization: {str(e)}\")\n",
    "    # Continue execution to allow manual table creation if needed\n",
    "\n",
    "\n",
    "# --- 2. Threshold Selection ---\n",
    "st.header(\"2. Select Confidence Threshold\")\n",
    "st.caption(\"Move the slider to see how the matched/unmatched split changes instantly.\")\n",
    "\n",
    "# Use a slider in the 60-100% range for easier user input (step 5%)\n",
    "selected_threshold_percent = st.slider(\n",
    "    \"Minimum Enhanced Confidence for MATCHED Records:\",\n",
    "    min_value=60, \n",
    "    max_value=100, \n",
    "    value=80, # Default to 80%\n",
    "    step=5,\n",
    "    format=\"‚â• %d%%\" # Show as percentage string\n",
    ")\n",
    "\n",
    "# Convert back to float 0.0-1.0 range for SQL query\n",
    "selected_threshold = selected_threshold_percent / 100.0 \n",
    "\n",
    "st.info(f\"üí° All records with **Enhanced Confidence $\\\\geq$ {selected_threshold_percent:.0f}%** will be flagged as MATCHED.\")\n",
    "\n",
    "# Calculate split preview (executed after slider change)\n",
    "split_preview = session.sql(f\"\"\"\n",
    "    SELECT \n",
    "        SUM(CASE WHEN enhanced_confidence >= {selected_threshold} THEN 1 ELSE 0 END) as matched_count,\n",
    "        SUM(CASE WHEN enhanced_confidence < {selected_threshold} THEN 1 ELSE 0 END) as unmatched_count,\n",
    "        COUNT(*) as total_count\n",
    "    FROM {results_table_name}\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "row = split_preview.iloc[0]\n",
    "total = int(row['TOTAL_COUNT'])\n",
    "matched = int(row['MATCHED_COUNT'])\n",
    "unmatched = int(row['UNMATCHED_COUNT'])\n",
    "\n",
    "# Use st.columns and st.metric for clear, consistent KPI display\n",
    "col1, col2, col3 = st.columns(3)\n",
    "with col1:\n",
    "    st.metric(\"Total Records\", f\"{total:,}\")\n",
    "with col2:\n",
    "    # REMOVED DELTA/ARROW: Combined count and percentage into the primary value field\n",
    "    matched_pct = round(matched / total * 100, 1) if total > 0 else 0\n",
    "    st.metric(\"Matched Records\", f\"{matched:,} ({matched_pct}%)\") \n",
    "with col3:\n",
    "    # REMOVED DELTA/ARROW: Combined count and percentage into the primary value field\n",
    "    unmatched_pct = round(unmatched / total * 100, 1) if total > 0 else 0\n",
    "    st.metric(\"Unmatched Records\", f\"{unmatched:,} ({unmatched_pct}%)\")\n",
    "\n",
    "\n",
    "# --- 3. Sample Preview (Hidden by default) ---\n",
    "# Update sample preview to show confidence as percent\n",
    "with st.expander(\"üëÅÔ∏è View Sample Results (Top 20 by Confidence)\"):\n",
    "    sample_results = session.sql(f\"\"\"\n",
    "        SELECT \n",
    "            reference_entity_name,\n",
    "            input_entity_name,\n",
    "            ROUND(enhanced_confidence * 100, 1) || '%' as enhanced_confidence_pct, -- Convert to percentage string\n",
    "            ROUND(vector_similarity * 100, 1) || '%' as vector_similarity_pct,\n",
    "            match_method,\n",
    "            CASE WHEN enhanced_confidence >= {selected_threshold} THEN '‚úÖ MATCHED' ELSE '‚ö†Ô∏è UNMATCHED' END as status\n",
    "        FROM {results_table_name}\n",
    "        ORDER BY enhanced_confidence DESC\n",
    "        LIMIT 20\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    # Rename columns for display\n",
    "    sample_results.columns = [\n",
    "        'Reference Entity', \n",
    "        'Input Entity', \n",
    "        'Enhanced Confidence', \n",
    "        'Vector Similarity', \n",
    "        'Match Method', \n",
    "        'Status'\n",
    "    ]\n",
    "    st.dataframe(sample_results, use_container_width=True)\n",
    "\n",
    "\n",
    "# --- 4. Configure & Create Tables ---\n",
    "st.header(\"4. Configure Output Table Names & Finalize\")\n",
    "# Generate sensible default names\n",
    "matched_table_name = f\"{audit_table_name}_HYBRID_MATCHED\"\n",
    "unmatched_table_name = f\"{audit_table_name}_HYBRID_UNMATCHED\"\n",
    "\n",
    "col_matched, col_unmatched = st.columns(2)\n",
    "\n",
    "with col_matched:\n",
    "    matched_table_input = st.text_input(\n",
    "        \"Matched Records Table Name:\",\n",
    "        value=matched_table_name\n",
    "    )\n",
    "\n",
    "with col_unmatched:\n",
    "    unmatched_table_input = st.text_input(\n",
    "        \"Unmatched Records Table Name:\",\n",
    "        value=unmatched_table_name\n",
    "    )\n",
    "\n",
    "if matched_table_input == unmatched_table_input:\n",
    "    st.error(\"‚ùå Table names must be different!\")\n",
    "else:\n",
    "    st.info(\"‚ö†Ô∏è Tables will be created using `CREATE OR REPLACE`. Existing tables will be overwritten.\")\n",
    "    \n",
    "    # Use a primary button for the final, irreversible action\n",
    "    if st.button(\"üöÄ Finalize & Create Output Tables\", type=\"primary\"):\n",
    "        with st.spinner(\"Creating tables...\"):\n",
    "            try:\n",
    "                # Create matched records table (SQL remains the same)\n",
    "                session.sql(f\"\"\"\n",
    "                    CREATE OR REPLACE TABLE {matched_table_input} AS\n",
    "                    SELECT *\n",
    "                    FROM {results_table_name}\n",
    "                    WHERE enhanced_confidence >= {selected_threshold}\n",
    "                \"\"\").collect()\n",
    "                \n",
    "                # Create unmatched records table (SQL remains the same)\n",
    "                session.sql(f\"\"\"\n",
    "                    CREATE OR REPLACE TABLE {unmatched_table_input} AS\n",
    "                    SELECT *\n",
    "                    FROM {results_table_name}\n",
    "                    WHERE enhanced_confidence < {selected_threshold}\n",
    "                \"\"\").collect()\n",
    "                \n",
    "                matched_df = session.sql(f\"SELECT COUNT(*) as cnt FROM {matched_table_input}\").to_pandas()\n",
    "                unmatched_df = session.sql(f\"SELECT COUNT(*) as cnt FROM {unmatched_table_input}\").to_pandas()\n",
    "                \n",
    "                # Handling case-insensitivity of SQL output column names\n",
    "                matched_count = int(matched_df.iloc[0]['CNT'])\n",
    "                unmatched_count = int(unmatched_df.iloc[0]['CNT'])\n",
    "                \n",
    "                # Create audit table to track table creation history\n",
    "                # Use fixed audit table name for the schema (not tied to specific audit table)\n",
    "                hybrid_audit_table = \"AUDIT_HARMONIZATION_HYBRID_AUDIT\"\n",
    "                \n",
    "                # Get reference and input table names from config\n",
    "                ref_table_full = config_df.iloc[0]['reference_table']\n",
    "                inp_table_full = config_df.iloc[0]['input_table']\n",
    "                \n",
    "                # Create audit table if it doesn't exist\n",
    "                session.sql(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS {hybrid_audit_table} (\n",
    "                        unmatched_table_name VARCHAR,\n",
    "                        matched_table_name VARCHAR,\n",
    "                        reference_table_name VARCHAR,\n",
    "                        input_table_name VARCHAR,\n",
    "                        confidence_threshold FLOAT,\n",
    "                        matched_record_count INTEGER,\n",
    "                        unmatched_record_count INTEGER,\n",
    "                        created_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    "                    )\n",
    "                \"\"\").collect()\n",
    "                \n",
    "                # Insert audit record\n",
    "                session.sql(f\"\"\"\n",
    "                    INSERT INTO {hybrid_audit_table} (\n",
    "                        unmatched_table_name,\n",
    "                        matched_table_name,\n",
    "                        reference_table_name,\n",
    "                        input_table_name,\n",
    "                        confidence_threshold,\n",
    "                        matched_record_count,\n",
    "                        unmatched_record_count\n",
    "                    )\n",
    "                    VALUES (\n",
    "                        '{unmatched_table_input}',\n",
    "                        '{matched_table_input}',\n",
    "                        '{ref_table_full}',\n",
    "                        '{inp_table_full}',\n",
    "                        {selected_threshold},\n",
    "                        {matched_count},\n",
    "                        {unmatched_count}\n",
    "                    )\n",
    "                \"\"\").collect()\n",
    "                \n",
    "                # st.balloons() REMOVED per user request\n",
    "                st.success(f\"üéâ **Tables created successfully!**\")\n",
    "                # Update markdown to use percentage format\n",
    "                st.markdown(f\"**{matched_table_input}**: {matched_count:,} records (Confidence $\\\\geq$ {selected_threshold_percent:.0f}%)\")\n",
    "                st.markdown(f\"**{unmatched_table_input}**: {unmatched_count:,} records (Confidence $<$ {selected_threshold_percent:.0f}%)\")\n",
    "                st.markdown(f\"**{hybrid_audit_table}**: Audit record created with timestamp\")\n",
    "                st.info(\"You can now use these tables for further analysis or downstream processing.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"‚ùå Error creating tables: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "collapsed": false,
    "name": "Performance_Explanation"
   },
   "source": [
    "## ‚ÑπÔ∏è Performance Evaluation and Analysis\n",
    "\n",
    "**What This Cell Does**: This cell evaluates the hybrid matching results against ground truth data to measure accuracy, precision, and recall. It compares the hybrid approach against other methods (if available) and provides detailed breakdowns by match method, confidence levels, and AI_CLASSIFY usage patterns.\n",
    "\n",
    "**Why This Is Important**: Evaluation is crucial for understanding the effectiveness of the hybrid approach. This analysis shows how well the two-stage process performs, identifies where AI_CLASSIFY adds value, and provides insights into the cost-benefit trade-offs. The detailed breakdowns help optimize the approach and understand which cases benefit most from AI_CLASSIFY intervention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "sql",
    "name": "r_Performance_Evaluation",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Performance Evaluation and Analysis\n",
    "-- Evaluates hybrid matching results against ground truth with confidence-based breakdowns\n",
    "\n",
    "-- CTE to select a unique set of ground truth mappings\n",
    "WITH unique_ground_truth AS (\n",
    "    SELECT\n",
    "        IDBUY,\n",
    "        IDABT,\n",
    "        ROW_NUMBER() OVER(PARTITION BY IDBUY ORDER BY IDABT) as rn\n",
    "    FROM ABT_BEST_BUY.STRUCTURED.ABT_BEST_BUY_PERFECT_MAPPING\n",
    "),\n",
    "\n",
    "-- Hybrid evaluation with confidence buckets\n",
    "hybrid_evaluation AS (\n",
    "    SELECT\n",
    "        hfr.input_detail_column,\n",
    "        hfr.input_entity_name,\n",
    "        hfr.reference_detail_column,\n",
    "        hfr.enhanced_confidence,\n",
    "        hfr.vector_similarity,\n",
    "        hfr.match_method,\n",
    "        gm.IDBUY,\n",
    "        gm.IDABT,\n",
    "        -- Match evaluation against ground truth\n",
    "        (hfr.reference_detail_column = gm.IDABT) AS is_correct_match,\n",
    "        -- Confidence buckets\n",
    "        CASE \n",
    "            WHEN hfr.enhanced_confidence >= 1 THEN '1. Very High (‚â•1.0)'\n",
    "            WHEN hfr.enhanced_confidence >= 0.9 THEN '2. High (0.9-1.0)'\n",
    "            WHEN hfr.enhanced_confidence >= 0.8 THEN '3. Medium (0.8-0.9)'\n",
    "            WHEN hfr.enhanced_confidence >= 0.7 THEN '4. Low (0.7-0.8)'\n",
    "            WHEN hfr.enhanced_confidence >= 0.6 THEN '5. Very Low (0.6-0.7)'\n",
    "            ELSE '6. Very Low (<0.6)'\n",
    "        END as confidence_bucket\n",
    "    FROM hybrid_final_results hfr\n",
    "    INNER JOIN unique_ground_truth gm\n",
    "        ON hfr.input_detail_column = gm.IDBUY\n",
    "        \n",
    "    WHERE gm.rn = 1\n",
    ")\n",
    "\n",
    "-- Overall performance summary\n",
    "SELECT\n",
    "    'HYBRID VECTOR + AI_CLASSIFY - TOTAL' as metric_category,\n",
    "    COUNT(*) as total_evaluated,\n",
    "    SUM(CASE WHEN is_correct_match THEN 1 ELSE 0 END) as correct_matches,\n",
    "    ROUND(SUM(CASE WHEN is_correct_match THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as accuracy_percent,\n",
    "    ROUND(AVG(enhanced_confidence), 4) as avg_confidence,\n",
    "    ROUND(AVG(vector_similarity), 4) as avg_vector_similarity,\n",
    "    ROUND(AVG(CASE WHEN is_correct_match THEN enhanced_confidence ELSE NULL END), 4) as avg_confidence_correct,\n",
    "    ROUND(AVG(CASE WHEN NOT is_correct_match THEN enhanced_confidence ELSE NULL END), 4) as avg_confidence_incorrect\n",
    "FROM hybrid_evaluation\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Breakdown by confidence buckets\n",
    "SELECT\n",
    "    confidence_bucket as metric_category,\n",
    "    COUNT(*) as total_evaluated,\n",
    "    SUM(CASE WHEN is_correct_match THEN 1 ELSE 0 END) as correct_matches,\n",
    "    ROUND(SUM(CASE WHEN is_correct_match THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as accuracy_percent,\n",
    "    ROUND(AVG(enhanced_confidence), 4) as avg_confidence,\n",
    "    ROUND(AVG(vector_similarity), 4) as avg_vector_similarity,\n",
    "    ROUND(AVG(CASE WHEN is_correct_match THEN enhanced_confidence ELSE NULL END), 4) as avg_confidence_correct,\n",
    "    ROUND(AVG(CASE WHEN NOT is_correct_match THEN enhanced_confidence ELSE NULL END), 4) as avg_confidence_incorrect\n",
    "FROM hybrid_evaluation\n",
    "GROUP BY confidence_bucket\n",
    "\n",
    "\n",
    "ORDER BY metric_category;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "collapsed": false,
    "name": "Summary"
   },
   "source": [
    "## üîÜ Summary and Key Insights\n",
    "\n",
    "This hybrid entity matching approach successfully combines the speed of vector similarity with the intelligence of AI_CLASSIFY to deliver optimal performance and cost efficiency.\n",
    "\n",
    "### ‚ÑπÔ∏è  Key Benefits:\n",
    "\n",
    "1. **Optimal Performance**: High-confidence matches (‚â•0.8) are resolved quickly with vector similarity, while medium-confidence cases benefit from AI_CLASSIFY's contextual understanding.\n",
    "\n",
    "2. **Cost Efficiency**: AI_CLASSIFY is only used when there are multiple viable candidates, reducing unnecessary API calls and costs.\n",
    "\n",
    "3. **Proven Pattern**: Based on the successful AI_SIMILARITY + AI_CLASSIFY workflow from Snowflake's AI SQL guide, ensuring reliability and best practices.\n",
    "\n",
    "4. **Comprehensive Evaluation**: Detailed breakdowns show exactly where AI_CLASSIFY adds value and how different match methods perform.\n",
    "\n",
    "### üìà Expected Results:\n",
    "\n",
    "- **High Recall**: Combines vector similarity accuracy with AI_CLASSIFY intelligence\n",
    "- **Balanced Cost**: AI_CLASSIFY usage only when needed, typically 20-40% of cases\n",
    "- **Fast Processing**: Most matches resolved quickly with vector similarity\n",
    "- **Intelligent Fallback**: AI_CLASSIFY handles ambiguous cases effectively\n",
    "\n",
    "### üîß Usage Instructions:\n",
    "\n",
    "1. **Configuration & Setup**: Run the configuration cell, select your harmonization tables and entity columns, then click the button to validate and automatically set up the environment (combines steps 1 & 2)\n",
    "2. **Feature Engineering**: Run the vector feature engineering cell to create embeddings\n",
    "3. **Hybrid Matching**: Run the hybrid matching cell to perform the two-stage matching process\n",
    "4. **Record Management**: Select your confidence threshold and create matched/unmatched output tables\n",
    "5. **Evaluation**: Run the evaluation cell to analyze performance and results\n",
    "\n",
    "### üí° Key Insights:\n",
    "\n",
    "- **Match Method Distribution**: Shows how many matches use each method (AI_CLASSIFY, high-confidence vector, medium-confidence vector)\n",
    "- **AI_CLASSIFY Usage**: Indicates the percentage of cases where AI_CLASSIFY was used\n",
    "- **Performance Metrics**: Recall, precision, and confidence scores for each approach\n",
    "- **Cost Analysis**: Understanding of when AI_CLASSIFY adds value vs. when vector similarity is sufficient\n",
    "\n",
    "This hybrid approach provides the best balance between speed, accuracy, and cost for entity matching tasks, making it ideal for production environments where both performance and cost efficiency are critical.\n"
   ]
  }
 ]
}
